# -*- coding: utf-8 -*-
"""task 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WelP69i0ZEeP1MhreRyvHGxtexbeBm8-
"""

# ===============================
# PREDICTIVE ANALYSIS NOTEBOOK
# Feature Selection, Model Training, Evaluation
# Dataset: sklearn breast_cancer
# ===============================

# 1. Install & Import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import (
    accuracy_score, roc_auc_score, classification_report,
    confusion_matrix, roc_curve, auc
)

# 2. Load Dataset
data = load_breast_cancer(as_frame=True)
X = data.frame[data.feature_names]
y = data.target
df = pd.concat([X, pd.Series(y, name='target')], axis=1)

print("Dataset Shape:", df.shape)
df.head()

# 3. Train/Test Split + Scaling
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=42, stratify=y
)
scaler = StandardScaler()
X_train_s = scaler.fit_transform(X_train)
X_test_s = scaler.transform(X_test)

# 4. Feature Selection Methods

# 4.1 Univariate (SelectKBest)
k = 10
selector_kbest = SelectKBest(score_func=f_classif, k=k)
selector_kbest.fit(X_train_s, y_train)
mask_kbest = selector_kbest.get_support()
selected_kbest = X.columns[mask_kbest].tolist()

# 4.2 Recursive Feature Elimination (RFE)
lr = LogisticRegression(max_iter=500, solver='liblinear')
rfe = RFE(estimator=lr, n_features_to_select=10, step=1)
rfe.fit(X_train_s, y_train)
selected_rfe = X.columns[rfe.get_support()].tolist()

# 4.3 L1-based Selection
lr_l1 = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, max_iter=1000)
lr_l1.fit(X_train_s, y_train)
mask_l1 = np.abs(lr_l1.coef_)[0] > 1e-4
selected_l1 = X.columns[mask_l1].tolist()

# 5. Summary of Features
features_summary = pd.DataFrame({
    'feature': X.columns,
    'kbest': mask_kbest,
    'rfe': rfe.get_support(),
    'l1': mask_l1
})
features_summary['selected_count'] = features_summary[['kbest','rfe','l1']].sum(axis=1)
features_summary.sort_values(['selected_count','feature'], ascending=[False,True], inplace=True)
features_summary.head(15)

# Choose features selected by at least 2 methods
chosen_features = features_summary[features_summary['selected_count'] >= 2]['feature'].tolist()
if len(chosen_features) < 5:
    chosen_features = selected_kbest

print("Chosen Features:", chosen_features)

# 6. Reduced Dataset
X_train_sel = pd.DataFrame(X_train_s, columns=X.columns)[chosen_features]
X_test_sel = pd.DataFrame(X_test_s, columns=X.columns)[chosen_features]

# 7. Train & Evaluate Models
models = {
    'LogisticRegression': LogisticRegression(max_iter=1000, solver='liblinear'),
    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42),
    'GradientBoosting': GradientBoostingClassifier(random_state=42)
}

results = []
for name, model in models.items():
    model.fit(X_train_sel, y_train)
    y_pred = model.predict(X_test_sel)
    y_prob = model.predict_proba(X_test_sel)[:,1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)
    acc = accuracy_score(y_test, y_pred)
    roc = roc_auc_score(y_test, y_prob)
    cv_mean = cross_val_score(model, X_train_sel, y_train, cv=5, scoring='roc_auc').mean()
    results.append({'Model': name, 'Accuracy': acc, 'ROC_AUC': roc, 'CV_ROC_AUC': cv_mean})
    print(f"\n{name}")
    print(f"Accuracy: {acc:.4f}  ROC AUC: {roc:.4f}  CV ROC AUC: {cv_mean:.4f}")
    print("Classification Report:\n", classification_report(y_test, y_pred, digits=4))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# 8. Results Table
results_df = pd.DataFrame(results).sort_values('ROC_AUC', ascending=False)
print("\nModel Comparison:\n", results_df)

# 9. ROC Curves
plt.figure(figsize=(7,6))
for name, model in models.items():
    y_prob = model.predict_proba(X_test_sel)[:,1] if hasattr(model, 'predict_proba') else model.decision_function(X_test_sel)
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.3f})")

plt.plot([0,1],[0,1], linestyle='--', color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves")
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

